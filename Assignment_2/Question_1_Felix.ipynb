{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "1. Fashion MNIST \n",
    "- Loading data\n",
    "- creating train, validation and test set \n",
    "- create class names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "                   \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "#num_classes = 10\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[28, 28], opt = \"SGD\"): \n",
    "    model = keras.models.Sequential() \n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = eval(\"\".join([\"keras.optimizers.\",opt, \"(lr=learning_rate)\"]))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "            validation_data=(X_valid, y_valid),\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=5, min_delta=0.001)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "        \"n_hidden\": [0, 1, 2, 3],\n",
    "        \"n_neurons\": np.arange(1, 100),\n",
    "        \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "        \"opt\": [\"SGD\",\"Adam\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs for 43 minutes\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=300,\n",
    "                batch_size=50,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(patience=3, min_delta=0.001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rnd_search_cv.best_params_)\n",
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.evaluate(X_test, y_test)\n",
    "model.save(\"MLP_brute.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing search with KerasTuner:\n",
    "- l1&l2 regularization slowed down the search process by a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten())\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 6)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of neurons separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=30, max_value=515, step=31),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "    if hp.Boolean(\"dropout\"):\n",
    "        model.add(layers.Dropout(rate=0.25))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing tuner: https://medium.com/swlh/hyperparameter-tuning-in-keras-tensorflow-2-with-keras-tuner-randomsearch-hyperband-3e212647778f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=10,\n",
    "    num_initial_points=2,\n",
    "    seed=90,\n",
    "    directory=\"Task1\",\n",
    "    project_name=\"MLP\",\n",
    "    #overwrite=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuner.search(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the top 3 models.\n",
    "models_mlp = Tuner.get_best_models(num_models=3)\n",
    "best_model_mlp = models_mlp[0]\n",
    "# Build model\n",
    "best_model_mlp.build(input_shape=(None, 28, 28))\n",
    "best_model_mlp.summary()\n",
    "Tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_mlp.evaluate(X_test, y_test)\n",
    "best_model_mlp.save(\"best_mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model_mlp.fit(X_train, y_train, epochs=30, \n",
    "                        validation_data=(X_valid, y_valid))\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.gca().set_xlim(0,29)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "def build_model_cnn(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(\n",
    "        #adding filter \n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        # adding kernel size\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        #activation function\n",
    "        activation='relu',\n",
    "        input_shape=[28,28,1],\n",
    "        padding='same',)\n",
    "    )\n",
    "    model.add(\n",
    "    layers.MaxPooling2D(pool_size = 2\n",
    "    ),\n",
    "    )\n",
    "    # Tune the number of layers.\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Conv2D(\n",
    "                #adding filter \n",
    "                filters=hp.Int(f'conv_{i}_filter', min_value=32, max_value=128, step=16),\n",
    "                # adding kernel size\n",
    "                kernel_size=hp.Choice(f'conv_{i}_kernel', values = [3,5]),\n",
    "                #activation function\n",
    "                activation='relu',\n",
    "                padding='same'),\n",
    "        )\n",
    "        model.add(\n",
    "            layers.MaxPooling2D(\n",
    "                pool_size = hp.Choice(f'pool_{i}_size', values = [2,4,6])\n",
    "            ),\n",
    "            )\n",
    "            \n",
    "    model.add(layers.Flatten())        \n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 2)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=60, max_value=515, step=20),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),),\n",
    "        )\n",
    "        \n",
    "        if hp.Boolean(\"dropout\"):\n",
    "            model.add(layers.Dropout(rate=hp.Choice(f'rate_{i}', values = [0.25,0.5,0.75])))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "build_model_cnn(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=build_model_cnn,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=20,\n",
    "    num_initial_points=2,\n",
    "    seed=90,\n",
    "    directory=\"Task1\",\n",
    "    project_name=\"CNN\",\n",
    "    #overwrite=True,\n",
    "    #executions_per_trial,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid), batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 models.\n",
    "models_cnn = tuner.get_best_models(num_models=3)\n",
    "best_model_cnn = models_cnn[0]\n",
    "# Build model\n",
    "best_model_cnn.build(input_shape=(None, 28, 28))\n",
    "best_model_cnn.summary()\n",
    "#tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cnn.evaluate(X_test, y_test)\n",
    "best_model_cnn.save(\"best_cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(x_train_full_cif, y_train_full_cif), (x_test_full_cif, y_test_full_cif) = cifar10.load_data()\n",
    "X_valid, X_train = x_train_full_cif[:5000] / 255.0, x_train_full_cif[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full_cif[:5000], y_train_full_cif[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp_cifar = keras.models.load_model(\"best_mlp.h5\")\n",
    "model_cnn_cifar = keras.models.load_model(\"best_cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn_cifar.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5)) \n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1] plt.show()\n",
    "model_cnn_cifar.evaluate(x_test_full_cif, y_test_full_cif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov  4 2022, 16:35:55) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "465081b95da0388f01304ae56a60c88a466aa07cc2dfde89eacbd1030b57bc71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
